{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    " \n",
    "# Ensembles and Random Forests\n",
    " \n",
    "_Author: Joseph Nelson (DC)_\n",
    "\n",
    "*Adapted from Chapter 8 of [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/)*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "Students will be able to:\n",
    "\n",
    "- Understand how and why decision trees can be improved using bagging and random forests.\n",
    "- Build random forest models for classification and regression.\n",
    "- Know how to extract the most important predictors in a random forest model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Guide\n",
    "- [Introduction](#introduction)\n",
    "- [Part 1: Manual Ensembling](#part-one)\n",
    "- [Part 2: Bagging](#part-two)\n",
    "    - [Manually Implementing Bagged Decision Trees](#manual-bagged)\n",
    "    - [Bagged Decision Trees in `scikit-learn`](#manual-sklearn)\n",
    "    - [Estimating Out-of-Sample Error](#oos-error)\n",
    "    \n",
    "    \n",
    "- [Part 3: Random Forests](#part-three)\n",
    "- [Part 4: Building and Tuning Decision Trees and Random Forests](#part-four)\n",
    "    - [Optional: Predicting Salary With a Decision Tree](#decision-tree)\n",
    "    - [Predicting Salary With a Random Forest](#random-forest-demo)\n",
    "    - [Comparing Random Forests With Decision Trees](#comparing)\n",
    "    \n",
    "    \n",
    "- [Optional: Tuning Individual Parameters](#tuning)\n",
    "- [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"introduction\"></a>\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Ensembling?\n",
    "\n",
    "**Ensemble learning (or \"ensembling\")** is the process of combining several predictive models in order to produce a combined model that is more accurate than any individual part. For example, given predictions from several models we could:\n",
    "\n",
    "- **Regression:** Take the average of the predictions.\n",
    "- **Classification:** Take a vote and use the most common prediction.\n",
    "\n",
    "For ensembling to work well, the models must be:\n",
    "\n",
    "- **Accurate:** They outperform the null model.\n",
    "- **Independent:** Their predictions are generated using different processes.\n",
    "\n",
    "**The big idea:** If you have a collection of individually imperfect (and independent) models, the \"one-off\" mistakes made by each model are probably not going to be made by the rest of the models, and thus the mistakes will be discarded when you average the models. In other words, several models can compensate each other.\n",
    "\n",
    "There are two basic **methods for ensembling:**\n",
    "\n",
    "- Manually ensembling your individual models.\n",
    "- Using a model that ensembles for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part-one\"></a>\n",
    "## Manual Ensembling\n",
    "\n",
    "What makes an effective manual ensemble?\n",
    "\n",
    "- Different types of **models**.\n",
    "- Different combinations of **features**.\n",
    "- Different **tuning parameters**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Machine learning flowchart](assets/crowdflower_ensembling.jpg)\n",
    "\n",
    "*Machine learning flowchart created by the [winner](https://github.com/ChenglongChen/Kaggle_CrowdFlower) of Kaggle's [CrowdFlower competition](https://www.kaggle.com/c/crowdflower-search-relevance)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Manual Ensembling With a Single Model Approach\n",
    "\n",
    "**Advantages of manual ensembling:**\n",
    "\n",
    "- It increases predictive accuracy.\n",
    "- It's easy to get started.\n",
    "\n",
    "**Disadvantages of manual ensembling:**\n",
    "\n",
    "- It decreases interpretability.\n",
    "- It takes longer to train.\n",
    "- It takes longer to predict.\n",
    "- It is more complex to automate and maintain.\n",
    "- Small gains in accuracy may not be worth the added complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part-two\"></a>\n",
    "## Bagging\n",
    "\n",
    "The primary weakness of **decision trees** is that they don't tend to have the best predictive accuracy. This is partially because of **high variance**, meaning that different splits in the training data can lead to very different trees.\n",
    "\n",
    "**Bagging** is a general-purpose procedure for reducing the variance of a machine learning method but is particularly useful for decision trees. Bagging is short for **bootstrap aggregation**, meaning the aggregation of bootstrap samples.\n",
    "\n",
    "A **bootstrap sample** is a random sample with replacement. So, it has the same size as the original sample but might duplicate some of the original observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.figsize'] = (10, 8)\n",
    "plt.rcParams['axes.titlesize'] = 20\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "[ 6 12 13  9 10 12  6 16  1 17  2 13  8 14  7 19  6 19 12 11]\n"
     ]
    }
   ],
   "source": [
    "# Set a seed for reproducibility.\n",
    "np.random.seed(1)\n",
    "\n",
    "# Create an array of 1 through 20.\n",
    "nums = np.arange(1, 21)\n",
    "print(nums)\n",
    "\n",
    "# Sample that array 20 times with replacement.\n",
    "print(np.random.choice(a=nums, size=20, replace=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does bagging work for decision trees?**\n",
    "\n",
    "1. Grow $B$ trees using $B$ bootstrap samples from the training data.\n",
    "2. Train each tree on its bootstrap sample and make predictions.\n",
    "3. Combine the predictions:\n",
    "    - Average the predictions for **regression trees**.\n",
    "    - Take a vote for **classification trees**.\n",
    "\n",
    "Notes:\n",
    "\n",
    "- **Each bootstrap sample** should be the same size as the original training set. (It may contain repeated rows.)\n",
    "- **$B$** should be a large enough value that the error seems to have \"stabilised\".\n",
    "- The trees are **grown deep** so that they have low bias/high variance.\n",
    "\n",
    "Bagging increases predictive accuracy by **reducing the variance**, similar to how cross-validation reduces the variance associated with train/test split (for estimating out-of-sample error) by splitting many times an averaging the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"manual-bagged\"></a>\n",
    "## Manually Implementing Bagged Decision Trees (with B=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>miles</th>\n",
       "      <th>doors</th>\n",
       "      <th>vtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22000</td>\n",
       "      <td>2012</td>\n",
       "      <td>13000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14000</td>\n",
       "      <td>2010</td>\n",
       "      <td>30000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13000</td>\n",
       "      <td>2010</td>\n",
       "      <td>73500</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9500</td>\n",
       "      <td>2009</td>\n",
       "      <td>78000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9000</td>\n",
       "      <td>2007</td>\n",
       "      <td>47000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4000</td>\n",
       "      <td>2006</td>\n",
       "      <td>124000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3000</td>\n",
       "      <td>2004</td>\n",
       "      <td>177000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000</td>\n",
       "      <td>2004</td>\n",
       "      <td>209000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3000</td>\n",
       "      <td>2003</td>\n",
       "      <td>138000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1900</td>\n",
       "      <td>2003</td>\n",
       "      <td>160000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2500</td>\n",
       "      <td>2003</td>\n",
       "      <td>190000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5000</td>\n",
       "      <td>2001</td>\n",
       "      <td>62000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1800</td>\n",
       "      <td>1999</td>\n",
       "      <td>163000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1300</td>\n",
       "      <td>1997</td>\n",
       "      <td>138000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price  year   miles  doors  vtype\n",
       "0   22000  2012   13000      2      0\n",
       "1   14000  2010   30000      2      0\n",
       "2   13000  2010   73500      4      0\n",
       "3    9500  2009   78000      4      0\n",
       "4    9000  2007   47000      4      0\n",
       "5    4000  2006  124000      2      0\n",
       "6    3000  2004  177000      4      0\n",
       "7    2000  2004  209000      4      1\n",
       "8    3000  2003  138000      2      0\n",
       "9    1900  2003  160000      4      0\n",
       "10   2500  2003  190000      2      1\n",
       "11   5000  2001   62000      4      0\n",
       "12   1800  1999  163000      2      1\n",
       "13   1300  1997  138000      4      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in and prepare the vehicle training data.\n",
    "\n",
    "path = './data/vehicles_train.csv'\n",
    "train = pd.read_csv(path)\n",
    "train['vtype'] = train.vtype.map({'car':0, 'truck':1})\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([13,  2, 12,  2,  6,  1,  3, 10, 11,  9,  6,  1,  0,  1]),\n",
       " array([ 9,  0,  0,  9,  3, 13,  4,  0,  0,  4,  1,  7,  3,  2]),\n",
       " array([ 4,  7,  2,  4,  8, 13,  0,  7,  9,  3, 12, 12,  4,  6]),\n",
       " array([ 1,  5,  6, 11,  2,  1, 12,  8,  3, 10,  5,  0, 11,  2]),\n",
       " array([10, 10,  6, 13,  2,  4, 11, 11, 13, 12,  4,  6, 13,  3]),\n",
       " array([10,  0,  6,  4,  7, 11,  6,  7,  1, 11, 10,  5,  7,  9]),\n",
       " array([ 2,  4,  8,  1, 12,  2,  1,  1,  3, 12,  5,  9,  0,  8]),\n",
       " array([11,  1,  6,  3,  3, 11,  5,  9,  7,  9,  2,  3, 11,  3]),\n",
       " array([ 3,  8,  6,  9,  7,  6,  3,  9,  6, 12,  6, 11,  6,  1]),\n",
       " array([13, 10,  3,  4,  3,  1, 13,  0,  5,  8, 13,  6, 11,  8])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a seed for reproducibility.\n",
    "np.random.seed(123)\n",
    "\n",
    "# Create ten bootstrap samples (which will be used to select rows from the DataFrame).\n",
    "samples = [np.random.choice(a=14, size=14, replace=True) for _ in range(1, 11)]\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>miles</th>\n",
       "      <th>doors</th>\n",
       "      <th>vtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1300</td>\n",
       "      <td>1997</td>\n",
       "      <td>138000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13000</td>\n",
       "      <td>2010</td>\n",
       "      <td>73500</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1800</td>\n",
       "      <td>1999</td>\n",
       "      <td>163000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13000</td>\n",
       "      <td>2010</td>\n",
       "      <td>73500</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3000</td>\n",
       "      <td>2004</td>\n",
       "      <td>177000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14000</td>\n",
       "      <td>2010</td>\n",
       "      <td>30000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9500</td>\n",
       "      <td>2009</td>\n",
       "      <td>78000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2500</td>\n",
       "      <td>2003</td>\n",
       "      <td>190000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5000</td>\n",
       "      <td>2001</td>\n",
       "      <td>62000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1900</td>\n",
       "      <td>2003</td>\n",
       "      <td>160000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3000</td>\n",
       "      <td>2004</td>\n",
       "      <td>177000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14000</td>\n",
       "      <td>2010</td>\n",
       "      <td>30000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22000</td>\n",
       "      <td>2012</td>\n",
       "      <td>13000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14000</td>\n",
       "      <td>2010</td>\n",
       "      <td>30000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price  year   miles  doors  vtype\n",
       "13   1300  1997  138000      4      0\n",
       "2   13000  2010   73500      4      0\n",
       "12   1800  1999  163000      2      1\n",
       "2   13000  2010   73500      4      0\n",
       "6    3000  2004  177000      4      0\n",
       "1   14000  2010   30000      2      0\n",
       "3    9500  2009   78000      4      0\n",
       "10   2500  2003  190000      2      1\n",
       "11   5000  2001   62000      4      0\n",
       "9    1900  2003  160000      4      0\n",
       "6    3000  2004  177000      4      0\n",
       "1   14000  2010   30000      2      0\n",
       "0   22000  2012   13000      2      0\n",
       "1   14000  2010   30000      2      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the rows for the first decision tree.\n",
    "train.iloc[samples[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>miles</th>\n",
       "      <th>doors</th>\n",
       "      <th>vtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000</td>\n",
       "      <td>2003</td>\n",
       "      <td>130000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6000</td>\n",
       "      <td>2005</td>\n",
       "      <td>82500</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12000</td>\n",
       "      <td>2010</td>\n",
       "      <td>60000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  year   miles  doors  vtype\n",
       "0   3000  2003  130000      4      1\n",
       "1   6000  2005   82500      4      0\n",
       "2  12000  2010   60000      2      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in and prepare the vehicle testing data.\n",
    "path = './data/vehicles_test.csv'\n",
    "test = pd.read_csv(path)\n",
    "test['vtype'] = test.vtype.map({'car':0, 'truck':1})\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1300.,  5000., 14000.],\n",
       "       [ 1300.,  1300., 13000.],\n",
       "       [ 3000.,  3000., 13000.],\n",
       "       [ 4000.,  5000., 13000.],\n",
       "       [ 1300.,  5000., 13000.],\n",
       "       [ 4000.,  5000., 14000.],\n",
       "       [ 4000.,  4000., 13000.],\n",
       "       [ 4000.,  5000., 13000.],\n",
       "       [ 3000.,  5000.,  9500.],\n",
       "       [ 4000.,  5000.,  9000.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Grow each tree deep.\n",
    "tree_reg = DecisionTreeRegressor(max_depth=None, random_state=123)\n",
    "\n",
    "# List for storing predicted price from each tree:\n",
    "predictions = []\n",
    "\n",
    "# Define testing data.\n",
    "X_test = test.iloc[:, 1:]\n",
    "y_test = test.iloc[:, 0]\n",
    "\n",
    "# Grow one tree for each bootstrap sample and make predictions on testing data.\n",
    "for sample in samples:\n",
    "    X_train = train.iloc[sample, 1:]\n",
    "    y_train = train.iloc[sample, 0]\n",
    "    tree_reg.fit(X_train, y_train)\n",
    "    y_pred = tree_reg.predict(X_test)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "# Convert predictions from list to NumPy array.\n",
    "predictions = np.array(predictions)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2990.,  4330., 12450.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average predictions.\n",
    "np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "998.5823284370031"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate RMSE.\n",
    "from sklearn import metrics\n",
    "\n",
    "y_pred = np.mean(predictions, axis=0)\n",
    "np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"manual-sklearn\"></a>\n",
    "## Bagged Decision Trees in `scikit-learn` (with B=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the training and testing sets.\n",
    "X_train = train.iloc[:, 1:]\n",
    "y_train = train.iloc[:, 0]\n",
    "X_test = test.iloc[:, 1:]\n",
    "y_test = test.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instruct BaggingRegressor to use DecisionTreeRegressor as the \"base estimator.\"\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "bagreg = BaggingRegressor(DecisionTreeRegressor(), n_estimators=500, \n",
    "                          bootstrap=True, oob_score=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3344.2,  5395. , 12902. ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and predict.\n",
    "bagreg.fit(X_train, y_train)\n",
    "y_pred = bagreg.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute '2f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-1eb18fe90df2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calculate RMSE and R squared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing RMSE:{.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing R squared:{0:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute '2f'"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE and R squared\n",
    "print(\"Testing RMSE:{0:.2f}\".format(np.sqrt(metrics.mean_squared_error(y_test, y_pred))))\n",
    "print(\"Testing R squared:{0:.2f}\".format(metrics.r2_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"oos-error\"></a>\n",
    "## Estimating Out-of-Sample Error\n",
    "\n",
    "For bagged models, out-of-sample error can be estimated without using **train/test split** or **cross-validation**!\n",
    "\n",
    "For each tree, the **unused observations** are called \"out-of-bag\" observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13,  2, 12,  2,  6,  1,  3, 10, 11,  9,  6,  1,  0,  1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first bootstrap sample.\n",
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 6, 9, 10, 11, 12, 13}\n",
      "{0, 1, 2, 3, 4, 7, 9, 13}\n",
      "{0, 2, 3, 4, 6, 7, 8, 9, 12, 13}\n",
      "{0, 1, 2, 3, 5, 6, 8, 10, 11, 12}\n",
      "{2, 3, 4, 6, 10, 11, 12, 13}\n",
      "{0, 1, 4, 5, 6, 7, 9, 10, 11}\n",
      "{0, 1, 2, 3, 4, 5, 8, 9, 12}\n",
      "{1, 2, 3, 5, 6, 7, 9, 11}\n",
      "{1, 3, 6, 7, 8, 9, 11, 12}\n",
      "{0, 1, 3, 4, 5, 6, 8, 10, 11, 13}\n"
     ]
    }
   ],
   "source": [
    "# Show the \"in-bag\" observations for each sample.\n",
    "for sample in samples:\n",
    "    print(set(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 7, 8]\n",
      "[5, 6, 8, 10, 11, 12]\n",
      "[1, 5, 10, 11]\n",
      "[4, 7, 9, 13]\n",
      "[0, 1, 5, 7, 8, 9]\n",
      "[2, 3, 8, 12, 13]\n",
      "[6, 7, 10, 11, 13]\n",
      "[0, 4, 8, 10, 12, 13]\n",
      "[0, 2, 4, 5, 10, 13]\n",
      "[2, 7, 9, 12]\n"
     ]
    }
   ],
   "source": [
    "# Show the \"out-of-bag\" observations for each sample.\n",
    "for sample in samples:\n",
    "    print(sorted(set(range(14)) - set(sample)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating \"out-of-bag error:\"**\n",
    "\n",
    "1. For each observation in the data, predict its response value using **only** the trees in which that observation was out-of-bag. Average those predictions (for regression) or take a vote (for classification).\n",
    "2. Compare all predictions to the actual response values in order to compute the out-of-bag error.\n",
    "\n",
    "When $B$ is sufficiently large, the **out-of-bag error** is an accurate estimate of **out-of-sample error**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-bag R squared: 0.80\n"
     ]
    }
   ],
   "source": [
    "# Compute the out-of-bag R-squared score (not MSE, unfortunately) for B=500.\n",
    "print(\"Out-of-bag R squared: {:0.2f}\".format(bagreg.oob_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating Feature Importance\n",
    "\n",
    "Bagging increases **predictive accuracy** but decreases **model interpretability** because it's no longer possible to visualize the tree to understand the importance of each feature.\n",
    "\n",
    "However, we can still obtain an overall summary of **feature importance** from bagged models:\n",
    "\n",
    "- **Bagged regression trees:** Calculate the total amount that **MSE** decreases due to splits over a given feature, averaged over all trees\n",
    "- **Bagged classification trees:** Calculate the total amount that **Gini index** decreases due to splits over a given feature, averaged over all trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part-three\"></a>\n",
    "## Random Forests\n",
    "\n",
    "Random Forests offer a **slight variation on bagged trees** with even better performance:\n",
    "\n",
    "- Exactly like bagging, a Random Forest an ensemble of Decision Trees created using bootstrapped samples of the training set.\n",
    "- However, the Random Forest algorithm introduces extra randomness when growing trees; instead of searching for the very best feature when splitting a node, it searches for the best feature among a **random subset of $m$ features** as opposed to the **full set of $p$ features**. This results in a greater tree diversity, which (once again) trades a higher bias for a lower variance, generally yielding an overall better model.\n",
    "- A new random sample of features is chosen for **every single tree at every single split**.\n",
    "\n",
    "\n",
    "For **classification**, $m$ is typically chosen to be the square root of $p$.\n",
    "For **regression**, $m$ is typically chosen to be somewhere between $p/3$ and $p$.\n",
    "\n",
    "What's the point?\n",
    "\n",
    "- Suppose there is **one very strong feature** in the data set. When using bagged trees, most of the trees will use that feature as the top split, resulting in an ensemble of similar trees that are **highly correlated**. In other words, when there are one or two strong features they might dominate every tree in bagging, resulting in essentially the same tree as every predictor.\n",
    "- Averaging highly correlated quantities does not significantly reduce variance (which is the entire goal of bagging).\n",
    "- By randomly leaving out candidate features from each split, **random forests \"decorrelate\" the trees** to the extent that the averaging process can reduce the variance of the resulting model. Using a subset of features to generate each tree allows us to get a wider variety of predictive trees that do not all use the same dominant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part-four\"></a>\n",
    "## Building and Tuning Decision Trees and Random Forests\n",
    "\n",
    "In this section, we will implement random forest algorithm in scikit-learn.\n",
    "\n",
    "- Major League Baseball player data from 1986-87: [data](https://github.com/justmarkham/DAT8/blob/master/data/hitters.csv), [data dictionary](https://cran.r-project.org/web/packages/ISLR/ISLR.pdf) (page 7)\n",
    "- Each observation represents a player.\n",
    "- **Goal:** Predict player salary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbourhood        0\n",
       "latitude             0\n",
       "longitude            0\n",
       "room_type            0\n",
       "minimum_nights       0\n",
       "number_of_reviews    0\n",
       "reviews_per_month    0\n",
       "availability_365     0\n",
       "price                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './data/sydney-airbnb.csv'\n",
    "airbnb = pd.read_csv(path)\n",
    "\n",
    "# Fill missing values with zeros\n",
    "airbnb.fillna(0, inplace=True)\n",
    "airbnb.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take a subset of data\n",
    "airbnb_ = airbnb[(airbnb.price > 0) & (airbnb.price < 1000)].copy()\n",
    "\n",
    "# Log transform the response variable\n",
    "airbnb_['log_price'] = np.log(airbnb_.price)\n",
    "\n",
    "# Encode categorical variable 'room_type\"\n",
    "#airbnb_['room_type'] = pd.factorize(airbnb_.room_type)[0]\n",
    "room_dummies = pd.get_dummies(airbnb_.room_type, prefix='', prefix_sep='', drop_first=True)\n",
    "room_dummies.columns = ['private_room', 'shared_room']\n",
    "\n",
    "# Concatenate the datasets\n",
    "airbnb_ = pd.concat([airbnb_, room_dummies], axis=1)\n",
    "airbnb_.drop('room_type', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define X and y.\n",
    "feature_cols = ['private_room', 'shared_room','latitude', 'longitude', 'availability_365', 'reviews_per_month']\n",
    "\n",
    "X = airbnb_[feature_cols]\n",
    "y = airbnb_.price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"decision-tree\"></a>\n",
    "## Exercise: Predicting Price With a Decision Tree\n",
    "\n",
    "Let's first recall how we might predict price using a single decision tree.\n",
    "\n",
    "Find the best **max_depth** for a decision tree using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of values to try for max_depth:\n",
    "max_depth_range = list(range(1, 21))\n",
    "\n",
    "# List to store the average RMSE for each value of max_depth:\n",
    "RMSE_scores = []\n",
    "\n",
    "# Use 10-fold cross-validation with each value of max_depth.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for depth in max_depth_range:\n",
    "    tree_reg = DecisionTreeRegressor(max_depth=depth, random_state=1)\n",
    "    MSE_scores = cross_val_score(tree_reg, X, y, cv=10, scoring='neg_mean_squared_error')\n",
    "    RMSE_scores.append(np.mean(np.sqrt(-MSE_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArIAAAIGCAYAAACoImzjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot max_depth (x-axis) versus RMSE (y-axis).\n",
    "plt.plot(max_depth_range, RMSE_scores);\n",
    "plt.xlabel('max_depth');\n",
    "plt.ylabel('RMSE (lower is better)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134.38995620711074, 7)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the best RMSE and the corresponding max_depth.\n",
    "sorted(zip(RMSE_scores, max_depth_range))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=7, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=1, splitter='best')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_depth=7 was best, so fit a tree using that parameter.\n",
    "tree_reg = DecisionTreeRegressor(max_depth=7, random_state=1)\n",
    "tree_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>private_room</td>\n",
       "      <td>0.527098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>longitude</td>\n",
       "      <td>0.145119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>latitude</td>\n",
       "      <td>0.109023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>reviews_per_month</td>\n",
       "      <td>0.103785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>availability_365</td>\n",
       "      <td>0.073248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shared_room</td>\n",
       "      <td>0.041727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature  importance\n",
       "0       private_room    0.527098\n",
       "3          longitude    0.145119\n",
       "2           latitude    0.109023\n",
       "5  reviews_per_month    0.103785\n",
       "4   availability_365    0.073248\n",
       "1        shared_room    0.041727"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute feature importances.\n",
    "pd.DataFrame({'feature':feature_cols, 'importance':tree_reg.feature_importances_}).\\\n",
    "sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"random-forest-demo\"></a>\n",
    "## Predicting Price With a Random Forest\n",
    "\n",
    "### Fitting a Random Forest With the Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=150,\n",
       "                      n_jobs=None, oob_score=True, random_state=1, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# n_estimators=150 is sufficiently large.\n",
    "rf_reg = RandomForestRegressor(n_estimators=150, oob_score=True, random_state=1)\n",
    "rf_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of bag R squared: 0.3609651506166798\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-ac8915fecb9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Find the average RMSE.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_squared_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    387\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 231\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 330\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1155\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1158\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Running this cell might take a few minutes!\n",
    "print(\"Out-of bag R squared:\", rf_reg.oob_score_)\n",
    "\n",
    "# Find the average RMSE.\n",
    "scores = cross_val_score(rf_reg, X, y, cv=10, scoring='neg_mean_squared_error')\n",
    "np.mean(np.sqrt(-scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>longitude</td>\n",
       "      <td>0.273050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>latitude</td>\n",
       "      <td>0.268037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>private_room</td>\n",
       "      <td>0.198141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>availability_365</td>\n",
       "      <td>0.136406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>reviews_per_month</td>\n",
       "      <td>0.107013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shared_room</td>\n",
       "      <td>0.017353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature  importance\n",
       "3          longitude    0.273050\n",
       "2           latitude    0.268037\n",
       "0       private_room    0.198141\n",
       "4   availability_365    0.136406\n",
       "5  reviews_per_month    0.107013\n",
       "1        shared_room    0.017353"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute feature importances.\n",
    "pd.DataFrame({'feature':feature_cols, 'importance':rf_reg.feature_importances_}).\\\n",
    "sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Reducing X to its Most Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36112, 6)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of X.\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** It important not to select features before separating your train from your test otherwise you are selecting features based on all known observations and introducing more of the information in the test data to the model when you fit it on the training data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27084, 6), (9028, 6))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 89)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features=4, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=150,\n",
       "                      n_jobs=None, oob_score=True, random_state=1, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model on only the train data\n",
    "rf_reg = RandomForestRegressor(n_estimators=150, max_features=4, oob_score=True, random_state=1)\n",
    "rf_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27084, 3)\n",
      "(27084, 3)\n"
     ]
    }
   ],
   "source": [
    "# Set a threshold for which features to include.\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "print(SelectFromModel(rf_reg, threshold='mean', prefit=True).transform(X_train).shape)\n",
    "print(SelectFromModel(rf_reg, threshold='median', prefit=True).transform(X_train).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the fit model and the features from the train data to transform the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9028, 3)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new feature matrix that only includes important features.\n",
    "\n",
    "X_important =  SelectFromModel(rf_reg, threshold='mean', prefit=True).transform(X_test)\n",
    "X_important.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314.66052720112219"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the RMSE for a random forest that only includes important features.\n",
    "rfreg = RandomForestRegressor(n_estimators=150, max_features=3, random_state=1)\n",
    "\n",
    "scores = cross_val_score(rfreg, X_important, y_test, cv=10, scoring='neg_mean_squared_error')\n",
    "np.mean(np.sqrt(-scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the error slightly increased. Often parameter tuning is required to achieve optimal results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"comparing\"></a>\n",
    "## Comparing Random Forests With Decision Trees\n",
    "\n",
    "**Advantages of random forests:**\n",
    "\n",
    "- Their performance is competitive with the best supervised learning methods.\n",
    "- They provide a more reliable estimate of feature importance.\n",
    "- They allow you to estimate out-of-sample error without using train/test split or cross-validation.\n",
    "\n",
    "**Disadvantages of random forests:**\n",
    "\n",
    "- They are less interpretable.\n",
    "- They are slower to train.\n",
    "- They are slower to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tuning\"></a>\n",
    "## Optional: Tuning Individual Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfreg = RandomForestRegressor()\n",
    "rfreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning n_estimators\n",
    "\n",
    "One important tuning parameter is **n_estimators**, which represents the number of trees that should be grown. This should be a large enough value that the error seems to have \"stabilized.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of values to try for n_estimators:\n",
    "estimator_range = list(range(10, 310, 10))\n",
    "\n",
    "# List to store the average RMSE for each value of n_estimators:\n",
    "RMSE_scores = []\n",
    "\n",
    "# Use five-fold cross-validation with each value of n_estimators (Warning: Slow!).\n",
    "for estimator in estimator_range:\n",
    "    rfreg = RandomForestRegressor(n_estimators=estimator, random_state=1)\n",
    "    MSE_scores = cross_val_score(rfreg, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    RMSE_scores.append(np.mean(np.sqrt(-MSE_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAELCAYAAADDZxFQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1183e9160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot RMSE (y-axis) versus n_estimators (x-axis).\n",
    "\n",
    "plt.plot(estimator_range, RMSE_scores);\n",
    "\n",
    "plt.xlabel('n_estimators');\n",
    "plt.ylabel('RMSE (lower is better)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_** In theory, the RMSE will continue to decrease and eventually level out.  Adding more estimators will neither (noticably)increase or decrease the RMSE (or other loss metric). However, introduction of noise can lead to random spikes as the n_estimators changes. This example is particularly interesting as after about 120 estimators the RMSE seems to steadily rise as more estimators are added.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning max_features\n",
    "\n",
    "The other important tuning parameter is **max_features**, which represents the number of features that should be considered at each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of values to try for max_features:\n",
    "feature_range = list(range(1, len(feature_cols)+1))\n",
    "\n",
    "# List to store the average RMSE for each value of max_features:\n",
    "RMSE_scores = []\n",
    "\n",
    "# Use 10-fold cross-validation with each value of max_features (Warning: Super slow!).\n",
    "for feature in feature_range:\n",
    "    rfreg = RandomForestRegressor(n_estimators=150, max_features=feature, random_state=1)\n",
    "    MSE_scores = cross_val_score(rfreg, X, y, cv=10, scoring='neg_mean_squared_error')\n",
    "    RMSE_scores.append(np.mean(np.sqrt(-MSE_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAELCAYAAADDZxFQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPdN8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118349748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot max_features (x-axis) versus RMSE (y-axis).\n",
    "\n",
    "plt.plot(feature_range, RMSE_scores);\n",
    "\n",
    "plt.xlabel('max_features');\n",
    "plt.ylabel('RMSE (lower is better)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290.00785113284348, 10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the best RMSE and the corresponding max_features.\n",
    "sorted(zip(RMSE_scores, feature_range))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"summary\"></a>\n",
    "## Summary\n",
    "\n",
    "**Which model is best?** The best classifier for a particular task is task-dependent. In many business cases, interpretability is more important than accuracy. So, decision trees may be preferred. In other cases, accuracy on unseen data might be paramount, in which case random forests would likely be better (since they typically overfit less). \n",
    "\n",
    "Remember that every model is a tradeoff between bias and variance. Ensemble models attempt to reduce overfitting by reducing variance but increasing bias (as compared to decision trees). By making the model more stable, we necessarily make it fit the training data less accurately. In some cases this is desired (particularly if we start with lots of overfitting), but for more simply structured data a simple decision tree might be best.\n",
    "\n",
    "---\n",
    "\n",
    "**In this lesson:**\n",
    "\n",
    "- We looked at ensemble models.\n",
    "\n",
    "- We saw how decision trees could be extended using two ensemble techniques -- bagging and random forests.\n",
    "\n",
    "- We looked at methods of evaluating feature importance and tuning parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
