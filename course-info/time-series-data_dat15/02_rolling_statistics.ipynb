{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Time Series: Rolling Statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "**After this lesson, you will be able to:**\n",
    "- Define the concepts of trend and seasonality and be able to identify them visually.\n",
    "- Use boxplots to compare distributions.\n",
    "- Plot time series data over time to identify large-scale trends in data.\n",
    "- Investigate trends by computing simple aggregates with Pandas using the `.resample()` function.\n",
    "- Compute rolling statistics with Pandas to compare data of a date to a smaller window of time.\n",
    "- Utilize exponentially weighted windows to average out noise.\n",
    "- Use differences to remove trends in time series data.\n",
    "- Use the Pandas' `.shift()` function to create lagged features.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Guide\n",
    "\n",
    "**Time Series Rolling Statistics**\n",
    "- [Trend and Seasonality](#A)\n",
    "- [Aggregate Data](#B)\n",
    "- [Rolling Statistics](#C)\n",
    "- [Differencing a Time Series and Stationarity](#D)\n",
    "- [Shifting and Lagging Time Series Data](#E)\n",
    "- [Independent Practice](#F)\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"A\">Trend and Seasonality</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What constitutes a trend in data? Is linearity required for a trend?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A trend is any long-term change in the value we are measuring. Trends may “change direction,” going from an increasing trend to a decreasing trend.\n",
    "\n",
    "- Trends can only be measured within the scope of the data collected; there may be trends that are unmeasurable if the data are not complete.\n",
    "\n",
    "An example of an upward trend:\n",
    "![](./assets/trend-line2.png)\n",
    "\n",
    "- When patterns repeat over *known, fixed periods* of time within a data set, we call this **seasonality**.\n",
    "\n",
    "- A seasonal pattern exists when a series is influenced by factors related to the cyclic nature of time — i.e., time of month, quarter, year, etc. Seasonality is of a fixed and known period, otherwise it is not truly seasonality. Additionally, it must be either attributed to another factor or counted as a set of anomalous events in the data.\n",
    "\n",
    ">  Can you think of some seasonal patterns from your own experience?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The easiest way to visualize trends is by drawing trend lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 8]\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Import the data.\n",
    "df = pd.read_csv('data/mapquest_google_trends.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean/organise the data. \n",
    "df.columns = ['WeekOf', 'Hits']\n",
    "print(df.head())\n",
    "\n",
    "ax = df.plot(title = \"Interest in MapQuest Over Time\")\n",
    "ax.set_xlabel(\"Week\");\n",
    "ax.set_ylabel(\"Hits\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit a Polynomial Regression of degree 1 (i.e. a Linear Regression) to compute a coefficient and y-intercept for our line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "X = np.array(df.index).reshape(-1, 1)\n",
    "y = np.array(df['Hits']).reshape(-1, 1)\n",
    "\n",
    "lin_reg.fit(X, y)\n",
    "\n",
    "print(lin_reg.coef_, lin_reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can use NumPy's [`polyfit()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.polyfit.html) method to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_coef = np.polyfit(df.index, df['Hits'], 1)\n",
    "print(line_coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, define our polynomial function using the obtained coefficients. We can do this on a single dimension using NumPy's [`poly1d()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.poly1d.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial = np.poly1d(line_coef)\n",
    "# The intercept is ~86.59, the slope is ~0.11.\n",
    "\n",
    "# Let's take a look at the trendline values at specific points:\n",
    "print(polynomial(0))\n",
    "print(polynomial(1))\n",
    "print(polynomial(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, plot our trendline over the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time series.\n",
    "plt.plot(df.index, df['Hits']);\n",
    "# Plot the least squares minimizing line.\n",
    "plt.plot(df.index, polynomial(df.index));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a second-order polynomial might fit our data even better. Let's try that out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_coef = np.polyfit(df.index,df['Hits'],2)\n",
    "print(line_coef)\n",
    "\n",
    "second_polynomial = np.poly1d(line_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time series.\n",
    "plt.plot(df.index, df['Hits']);\n",
    "# Plot the least squares minimizing line.\n",
    "plt.plot(df.index, second_polynomial(df.index));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question:** Can you think of any other underlying patterns that might cause trends in time series data? What might cause seasonality in a time series?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guided Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look for trends and seasonality in data made available by a German drugstore, Rossmann.\n",
    "\n",
    "These data contain the daily sales made at the drugstore, as well as whether or not a sale or holiday affected the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we want to explore the trend over time, we will make sure to convert the `Date` column to a `datetime` object and make it the index of our DataFrame, as we did with our Apple stock data. \n",
    "\n",
    "Let's recall the steps for preprocessing time series data with Pandas:\n",
    "* Convert time data to a `datetime` object.\n",
    "* Set `datetime` to index the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 8]\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pharm = pd.read_csv('data/rossmann.csv', skipinitialspace=True, low_memory=False)\n",
    "pharm['Date'] = pd.to_datetime(pharm['Date'])\n",
    "pharm = pharm.set_index('Date')\n",
    "print(\"{} rows by {} columns\".format(pharm.shape[0], pharm.shape[1]))\n",
    "pharm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to easily filter by date. Let's add a column for `Year` and `Month` based on the `datetime` index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pharm['Year'] = pharm.index.year\n",
    "pharm['Month'] = pharm.index.month\n",
    "\n",
    "pharm['2015-05'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more than a million sales data points in this data set, so, for some simple exploratory data analysis (EDA), we'll focus on just one store.\n",
    "\n",
    "*Note: We explicitly add a `.copy()` to the returned DataFrame because we will be making changes to this DataFrame object later. If we didn't specify this, we will receive SettingCopyWarnings later on because Pandas will not know if we want to edit a view of the original data object (`data`) or a separate data object (`store1_data`). Without the `.copy()`, the variable `store1_data` will simply be a reference the original data object in memory.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pharm_store1 = pharm[pharm['Store'] == 1].copy()\n",
    "print(\"{} rows by {} columns\".format(pharm_store1.shape[0], pharm_store1.shape[1]))\n",
    "pharm_store1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the sales data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's investigate whether or not promotions affect sales. For this, we'll use boxplots.\n",
    "\n",
    "On state holidays, the store is closed (which means there are zero sales), so we need to cut those days out. (Contextual knowledge like this is always necessary to truly explain time series phenomena.)\n",
    "\n",
    "> **Check for Understanding:** Can you think of any other special considerations we should make when tracking sales?\n",
    "\n",
    "Now, check to see if there is a difference affecting sales on promotion days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Promo', y='Sales', data=pharm_store1[pharm_store1['Open']==1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there _is_ a difference in sales on promotion days.\n",
    "\n",
    "Why is it important to separate out days on which the store is closed? Because there aren't any promotions on those days either, so including them will bias our sales data on days without promotions! Remember to think about the business logic in addition to analyzing the raw data.\n",
    "\n",
    "We may also want to compare sales across days of the week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='DayOfWeek', y='Sales', data=pharm_store1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we want to identify larger-scale trends in our data. How did sales change from 2014 to 2015? Were there any particularly interesting outliers in terms of sales or customer visits?\n",
    "\n",
    "To plot the sales and customer visits over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to days Store 1 was open.\n",
    "pharm_store1_open = pharm_store1[pharm_store1['Open']==1]\n",
    "pharm_store1_open[['Sales']].plot();\n",
    "pharm_store1_open[['Customers']].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are large spikes of sales and customers toward the end of 2013 and 2014, leading into the first quarter of 2014 and 2015.\n",
    "\n",
    "Let's use index filtering to filter just to 2014 changes over time. This should make it easier to identify the holiday sales bump.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pharm_store1_2014 = pharm_store1_open['2014']\n",
    "pharm_store1_2014[['Sales']].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id= \"B\">Aggregate Data</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to investigate trends over time in sales, as always, we should start by computing simple aggregates. We want to know: What were the mean and median sales in each month and year?\n",
    "\n",
    "We can use `pharm.resample` on the whole data set and provide:\n",
    "    - A parameter for the level on which to roll up to: `'D'` for day, `'W'` for week, `'M'` for month, `'A'` for year.\n",
    "    - The aggregation method to perform: `mean()`, `median()`, `sum()`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pharm[['Sales']].resample('A').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like average sales were highest in 2015. Now, let's look at the median annual sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pharm[['Sales']].resample('A').median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pharm[['Sales']].resample('M').mean().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information, see Pandas' `.resample`  [documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.resample.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question:** How do aggregation techniques help us sort out important insights from the noise of time series data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id= \"C\">Rolling Statistics</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With time series, we can \"roll\" statistics across time. For example, the rolling mean is the mean of a moving window across time periods. To understand holidays sales in pharmacies, we don't want to compare sales data in late December with the entire month but instead with a few days immediately surrounding it. We can do this using rolling averages.\n",
    "\n",
    "![](./assets/rolling-statistics.jpeg)\n",
    "\n",
    "\n",
    "### Parameters for `rolling()` Functions\n",
    "\n",
    "Pandas offers a variety of functionalities for creating rolling statistics, which we'll only scratch the surface of here.  We'll be using a `rolling()` function with parameters `window` and `center` and a statistical function chained to it. Let's dive into more detail.\n",
    "\n",
    "[`rolling()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rolling.html) can take the following parameters:\n",
    "\n",
    "* `window` indicates the number of observations used for calculating the statistic.\n",
    "* `center` indicates whether the window should be centered on the date or use data prior to that date.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate the rolling daily sum over all stores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `.resample()` function to calculate the daily total over all of the stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_pharm_sales = pharm[['Sales']].resample('D').sum()\n",
    "daily_pharm_sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `.rolling()` function to calculate the rolling average over a three-day period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_pharm_sales.rolling(window=3, center=True).mean().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Why is there a NaN in the first row? What if we set the parameter `window` to 6?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use our index filtering to just look at 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_pharm_sales.rolling(window=7, center=True).mean()['2015'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of plotting the full time series, we can plot the rolling mean, which smooths random changes in sales and removes outliers, helping us identify larger trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "daily_pharm_sales.rolling(window=30, center=True).mean().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note that rolling doesn't understand if you are missing periods (e.g., if you roll over three days and your data are missing weekends, it'll roll Fri/Sat/Sun), so you need to resample first if you care about that.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question:** How does the signal that's captured by rolling statistics differ from the signal captured by resampling time series data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Expanding Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expanding mean simply uses all of the data points up to the current time to calculate the mean, as opposed to a moving window.\n",
    "\n",
    "![](./assets/expanding-mean.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate and plot the expanding mean and compare it to the rolling mean. Resample by month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_pharm_sales = pharm.Sales.resample('M').sum()\n",
    "monthly_pharm_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rolling_mean = monthly_pharm_sales.rolling(window=3, center=False).mean()\n",
    "expanding_mean = monthly_pharm_sales.expanding().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "rolling_mean.plot(legend = True);\n",
    "expanding_mean.plot(legend = True);\n",
    "ax.legend(['Rolling Mean', 'Expanding Mean']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponentially Weighted Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponentially weighted windows are one of the most common and effective ways of averaging out noise in time series data. The averaging is done with an \"exponential decay\" on the contribution of prior means, decreasing the contribution of time points that are further in the past.\n",
    "\n",
    "The (adjusted) exponentially weighted mean for time, $t$, is defined as:\n",
    "\n",
    "$$ x_t = \\frac{x_t + (1 - \\alpha)x_{t-1} + (1 - \\alpha)^2x_{t-1} + ... + (1 - \\alpha)^{t}x_0} {1 + (1 - \\alpha) + (1 - \\alpha)^2 + ... + (1 - \\alpha)^{t}} $$\n",
    "\n",
    "Pandas provides the function [`.ewm()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.ewm.html) to calculate the exponentially weighted mean.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate and plot the exponentially weighted sum along with the rolling sum. What's the difference?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_weighted_mean = monthly_pharm_sales.ewm(span=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "rolling_mean.plot(legend = True);\n",
    "expanding_mean.plot(legend = True);\n",
    "exp_weighted_mean.plot(legend = True);\n",
    "ax.legend(['Rolling Mean', 'Expanding Mean', 'Exponentially Weighted Mean']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"E\">Shifting and Lagging Time Series Data</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common operation on time series data is shifting or lagging values backward and forward in time. This can help us calculate the percentage of change from sample to sample. Pandas has a `.shift()` method for shifting the data in a DataFrame.\n",
    "\n",
    "Let's take a look at the Rossman data when we apply lagged features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pharm_store1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's shift the sales price by one day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_forward = pharm_store1.shift(1)\n",
    "shifted_forward.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notice that the first row now contains NaN values because there wasn't a previous day's data to shift to that day.*\n",
    "\n",
    "Next, let's shift the sales prices by five days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_forward5 = pharm_store1.shift(5)\n",
    "shifted_forward5.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use negative numbers to shift the sales values in the reverse direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_backward = pharm_store1.shift(-1)\n",
    "shifted_backward.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lags can be used to calculate the changes in the values you are tracking with your time series data. In this case, we can use Pandas' `.shift()` method to look at the changes in sales. \n",
    "\n",
    "Let's create a new column in our Rossman DataFrame that contains the previous day's sales. \n",
    "\n",
    "*Note that we added `.copy()` when we filtered out the store 1 sales earlier. If we didn't explictly tell Pandas that `store1_data` is a copy (instead of a view), we would receive a `SettingCopyWarning`. Here is a useful [video](https://www.youtube.com/watch?v=4R4WsDJ-KVc) that helps explain how to avoid SettingCopyWithWarning errors in Pandas.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pharm_store1['Prev Day Sales'] = pharm_store1['Sales'].shift(1)\n",
    "pharm_store1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Using our new column, it's simple to calculate the one-day change in sales at Store 1. Let's create a new column for this value in our DataFrame as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pharm_store1['Sales Change'] = pharm_store1['Sales'] - pharm_store1['Prev Day Sales']\n",
    "pharm_store1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question:** What are some other real-world applications you can think of for shifting data in a time series?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Takeaways**\n",
    "* Trends are long-term changes in data. We have to sort through the noise of a time series to identify trends.\n",
    "* We can resample the data to look at simple aggregates and identify patterns.\n",
    "* Rolling statistics give us a local statistic of an average in time, smoothing out random fluctuations and removing outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"F\">Independent Practice</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructor Note:** These are optional and can be assigned as student practice questions outside of class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Unemployment data set. Perform any necessary cleaning and preprocess the data by creating a `datetime` index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp = pd.read_csv('./data/unemployment.csv')\n",
    "unemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns in the dataset.\n",
    "unemp.columns = ['year_quarter', 'unemployment_rate']\n",
    "\n",
    "# Drop % and convert string to float\n",
    "unemp['unemployment_rate'] = unemp['unemployment_rate'].map(lambda x: float(str(x).replace('%','')))\n",
    "\n",
    "unemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN values.\n",
    "unemp.dropna(inplace=True)\n",
    "\n",
    "unemp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is quarterly data, so converting to datetime is a bit complicated. \n",
    "# Use .dt.to_period('Q') to help represent the string as a datetime object.\n",
    "unemp['date'] = \n",
    "# Set Date column to index.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the unemployment rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the rolling mean of years with `window=3 `, without centering, and plot both the unemployment rates and the rolling mean data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly = \n",
    "yearly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "unemp.unemployment_rate.plot(legend = True);\n",
    "yearly.plot(legend = True);\n",
    "ax.legend(['Unemployment Rate', 'Rolling mean of years']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the rolling median with `window=5` and `window=15`. Plot both together with the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roll_med_5 = \n",
    "roll_med_15 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "#Plot together the original data and both rolling medians."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and plot the expanding mean. Resample by quarter. Plot the rolling mean and the expanding mean together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_ticks = unemp.index.to_timestamp()\n",
    "\n",
    "# Resample by quarter.\n",
    "quarterly_data = \n",
    "\n",
    "# Calculate the rolling mean with window = 1 without centering.\n",
    "rolling_mean = \n",
    "\n",
    "# Calculate the expanding mean.\n",
    "expanding_mean = \n",
    "\n",
    "# Create a plot of the rolling/expanding mean vs date_ticks. Why this way to plot the data is better?\n",
    "plt.plot(date_ticks, rolling_mean, alpha=1, lw=2, label='Rolling mean')\n",
    "plt.plot(date_ticks, expanding_mean, alpha=1, lw=2, label='Expanding mean')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tick_params(labelsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate exponentially weighted sum and add to the previous plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_weighted_mean = \n",
    "\n",
    "# Plot together the rolling, expanding and exponentially weighted means."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
